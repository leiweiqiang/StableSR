#!/usr/bin/env python3
"""
æµ‹è¯•Edgeæ¨¡å‹åŠ è½½åŠŸèƒ½
éªŒè¯ä¿®å¤åçš„æ¨¡å‹åŠ è½½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
import torch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from edge_model_loader import load_edge_model, create_test_image, generate_edge_map


def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½åŠŸèƒ½"""
    print("æµ‹è¯•Edgeæ¨¡å‹åŠ è½½åŠŸèƒ½")
    print("="*40)
    
    # é…ç½®è·¯å¾„
    config_path = "configs/stableSRNew/v2-finetune_text_T_512_edge.yaml"
    ckpt_path = "/stablesr_dataset/checkpoints/stablesr_turbo.ckpt"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        print("è¯·ç¡®ä¿é…ç½®æ–‡ä»¶è·¯å¾„æ­£ç¡®")
        return False
    
    if not os.path.exists(ckpt_path):
        print(f"âŒ æ¨¡å‹æ£€æŸ¥ç‚¹ä¸å­˜åœ¨: {ckpt_path}")
        print("è¯·ç¡®ä¿æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„æ­£ç¡®")
        return False
    
    try:
        # æµ‹è¯•æ¨¡å‹åŠ è½½
        print("1. æµ‹è¯•æ¨¡å‹åŠ è½½...")
        model, sampler = load_edge_model(config_path, ckpt_path)
        print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•è®¾å¤‡
        print(f"2. æ¨¡å‹è®¾å¤‡: {next(model.parameters()).device}")
        
        # æµ‹è¯•edgeå¤„ç†æ”¯æŒ
        if hasattr(model, 'use_edge_processing') and model.use_edge_processing:
            print("âœ“ æ¨¡å‹æ”¯æŒedgeå¤„ç†")
        else:
            print("âš ï¸ æ¨¡å‹ä¸æ”¯æŒedgeå¤„ç†")
        
        # æµ‹è¯•åˆ›å»ºæµ‹è¯•å›¾åƒ
        print("3. æµ‹è¯•åˆ›å»ºæµ‹è¯•å›¾åƒ...")
        test_img = create_test_image()
        print(f"âœ“ æµ‹è¯•å›¾åƒåˆ›å»ºæˆåŠŸ: {test_img.shape}")
        
        # æµ‹è¯•edge mapç”Ÿæˆ
        print("4. æµ‹è¯•edge mapç”Ÿæˆ...")
        edge_map = generate_edge_map(test_img)
        print(f"âœ“ Edge mapç”ŸæˆæˆåŠŸ: {edge_map.shape}")
        
        # æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­ï¼ˆç®€å•æµ‹è¯•ï¼‰
        print("5. æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­...")
        with torch.no_grad():
            # åˆ›å»ºç®€å•çš„è¾“å…¥
            dummy_input = torch.randn(1, 4, 64, 64).to(next(model.parameters()).device)
            dummy_timesteps = torch.zeros(1, dtype=torch.long).to(next(model.parameters()).device)
            dummy_context = torch.randn(1, 77, 1024).to(next(model.parameters()).device)
            dummy_struct_cond = torch.randn(1, 256, 96, 96).to(next(model.parameters()).device)
            dummy_edge_map = torch.randn(1, 3, 512, 512).to(next(model.parameters()).device)
            
            # æµ‹è¯•UNetå‰å‘ä¼ æ’­
            try:
                output = model.model.diffusion_model(
                    dummy_input, 
                    dummy_timesteps, 
                    context=dummy_context,
                    struct_cond=dummy_struct_cond,
                    edge_map=dummy_edge_map
                )
                print(f"âœ“ æ¨¡å‹å‰å‘ä¼ æ’­æˆåŠŸ: {output.shape}")
            except Exception as e:
                print(f"âš ï¸ æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•å¤±è´¥: {e}")
                # è¿™å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºæ¨¡å‹å¯èƒ½éœ€è¦ç‰¹å®šçš„è¾“å…¥æ ¼å¼
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_without_model():
    """æµ‹è¯•ä¸ä¾èµ–æ¨¡å‹çš„åŠŸèƒ½"""
    print("\næµ‹è¯•ä¸ä¾èµ–æ¨¡å‹çš„åŠŸèƒ½")
    print("="*40)
    
    try:
        # æµ‹è¯•åˆ›å»ºæµ‹è¯•å›¾åƒ
        print("1. æµ‹è¯•åˆ›å»ºæµ‹è¯•å›¾åƒ...")
        test_img = create_test_image()
        print(f"âœ“ æµ‹è¯•å›¾åƒåˆ›å»ºæˆåŠŸ: {test_img.shape}")
        
        # æµ‹è¯•edge mapç”Ÿæˆ
        print("2. æµ‹è¯•edge mapç”Ÿæˆ...")
        edge_map = generate_edge_map(test_img)
        print(f"âœ“ Edge mapç”ŸæˆæˆåŠŸ: {edge_map.shape}")
        
        print("âœ“ åŸºç¡€åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ åŸºç¡€åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("StableSR Edgeæ¨¡å‹åŠ è½½æµ‹è¯•")
    print("="*50)
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    if torch.cuda.is_available():
        print(f"âœ“ CUDAå¯ç”¨: {torch.cuda.get_device_name()}")
        print(f"  æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
    
    # æµ‹è¯•åŸºç¡€åŠŸèƒ½ï¼ˆä¸ä¾èµ–æ¨¡å‹ï¼‰
    basic_test_passed = test_without_model()
    
    # æµ‹è¯•å®Œæ•´åŠŸèƒ½ï¼ˆä¾èµ–æ¨¡å‹ï¼‰
    if basic_test_passed:
        full_test_passed = test_model_loading()
        
        if full_test_passed:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Edgeæ¨¡å‹åŠ è½½åŠŸèƒ½æ­£å¸¸ã€‚")
            return 0
        else:
            print("\nâŒ æ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥ï¼Œä½†åŸºç¡€åŠŸèƒ½æ­£å¸¸ã€‚")
            print("å¯èƒ½çš„åŸå› ï¼š")
            print("1. æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ä¸æ­£ç¡®")
            print("2. é…ç½®æ–‡ä»¶è·¯å¾„ä¸æ­£ç¡®")
            print("3. æ¨¡å‹ç‰ˆæœ¬ä¸å…¼å®¹")
            return 1
    else:
        print("\nâŒ åŸºç¡€åŠŸèƒ½æµ‹è¯•å¤±è´¥ã€‚")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
