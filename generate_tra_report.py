#!/usr/bin/env python3
"""
ä½¿ç”¨TraReportç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
ä»…ä½¿ç”¨StableSR Edgeæ¨¡å‹ï¼Œé¿å…é…ç½®ä¸åŒ¹é…é—®é¢˜
"""

import os
import sys
import json
import tempfile
import shutil
from pathlib import Path
import torch
import numpy as np
from PIL import Image
import random
from datetime import datetime

# è®¾ç½®éšæœºç§å­
random.seed(42)
np.random.seed(42)
torch.manual_seed(42)

def create_test_subset(gt_dir, val_dir, num_samples=10):
    """åˆ›å»ºæµ‹è¯•å­é›†"""
    print(f"åˆ›å»ºåŒ…å« {num_samples} ä¸ªæ ·æœ¬çš„æµ‹è¯•å­é›†...")
    
    # è·å–æ‰€æœ‰æ–‡ä»¶
    gt_files = sorted([f for f in os.listdir(gt_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
    val_files = sorted([f for f in os.listdir(val_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
    
    # ç¡®ä¿æ–‡ä»¶åŒ¹é…
    matching_files = []
    for gt_file in gt_files:
        if gt_file in val_files:
            matching_files.append(gt_file)
    
    print(f"æ‰¾åˆ° {len(matching_files)} å¯¹åŒ¹é…çš„æ–‡ä»¶")
    
    # éšæœºé€‰æ‹©æ ·æœ¬
    selected_files = random.sample(matching_files, min(num_samples, len(matching_files)))
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp()
    temp_gt_dir = os.path.join(temp_dir, 'gt')
    temp_val_dir = os.path.join(temp_dir, 'val')
    os.makedirs(temp_gt_dir, exist_ok=True)
    os.makedirs(temp_val_dir, exist_ok=True)
    
    # å¤åˆ¶é€‰ä¸­çš„æ–‡ä»¶
    for file in selected_files:
        shutil.copy2(os.path.join(gt_dir, file), os.path.join(temp_gt_dir, file))
        shutil.copy2(os.path.join(val_dir, file), os.path.join(temp_val_dir, file))
    
    print(f"æµ‹è¯•å­é›†åˆ›å»ºå®Œæˆ: {temp_dir}")
    print(f"GTæ–‡ä»¶: {len(selected_files)} ä¸ª")
    print(f"Valæ–‡ä»¶: {len(selected_files)} ä¸ª")
    
    return temp_dir, temp_gt_dir, temp_val_dir

def generate_tra_report():
    """ç”ŸæˆTraReportè¯„ä¼°æŠ¥å‘Š"""
    print("=" * 80)
    print("TraReport è¯„ä¼°æŠ¥å‘Šç”Ÿæˆå™¨")
    print("=" * 80)
    
    try:
        from tra_report import TraReport
        print("âœ… TraReportå¯¼å…¥æˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        temp_dir, gt_dir, val_dir = create_test_subset(
            '/stablesr_dataset/dataset/DIV2K/DIV2K_valid_HR',
            '/stablesr_dataset/dataset/DIV2K/DIV2K_valid_LR',
            num_samples=10
        )
        
        # åˆå§‹åŒ–TraReport
        model_path = './logs/2025-10-05T01-24-44_stablesr_edge_T6_DIV2K_2005_10_04/checkpoints/last.ckpt'
        config_path = './configs/stableSRNew/v2-finetune_text_T_512_edge.yaml'
        
        print(f"ä½¿ç”¨æ¨¡å‹: {model_path}")
        print(f"ä½¿ç”¨é…ç½®: {config_path}")
        
        tra_report = TraReport(
            gt_dir=gt_dir,
            val_dir=val_dir,
            model_path=model_path,
            config_path=config_path,
            device='cuda',
            ddpm_steps=50,  # é€‚ä¸­çš„æ­¥æ•°
            upscale=4.0,
            colorfix_type='adain',
            seed=42
        )
        
        print("âœ… TraReportåˆå§‹åŒ–æˆåŠŸ")
        
        # è¿è¡Œè¯„ä¼°
        print("\nå¼€å§‹è¯„ä¼°...")
        results = tra_report.evaluate()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "evaluation_info": {
                "timestamp": datetime.now().isoformat(),
                "model_path": model_path,
                "config_path": config_path,
                "dataset": "DIV2K Validation Set",
                "num_samples": len(results.get("results", [])),
                "ddpm_steps": 50,
                "upscale_factor": 4.0,
                "colorfix_type": "adain",
                "device": "cuda"
            },
            "summary": {
                "total_images": len(results.get("results", [])),
                "average_psnr": results.get("average_psnr", 0),
                "best_psnr": results.get("best_psnr", 0),
                "worst_psnr": results.get("worst_psnr", 0)
            },
            "detailed_results": results.get("results", []),
            "model_info": {
                "model_type": "StableSR Edge",
                "parameters": "920.95M",
                "architecture": "LatentDiffusionSRTextWTWithEdge",
                "edge_processing": True
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        output_file = "tra_report_evaluation.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… è¯„ä¼°å®Œæˆï¼")
        print(f"ğŸ“Š è¯„ä¼°ç»“æœ:")
        print(f"  - å¤„ç†å›¾ç‰‡æ•°é‡: {report['summary']['total_images']}")
        print(f"  - å¹³å‡PSNR: {report['summary']['average_psnr']:.2f} dB")
        print(f"  - æœ€ä½³PSNR: {report['summary']['best_psnr']:.2f} dB")
        print(f"  - æœ€å·®PSNR: {report['summary']['worst_psnr']:.2f} dB")
        print(f"  - æŠ¥å‘Šæ–‡ä»¶: {output_file}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        shutil.rmtree(temp_dir)
        
        return report
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def generate_summary_report(report):
    """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
    if not report:
        return
    
    print("\n" + "=" * 80)
    print("TraReport è¯„ä¼°æ€»ç»“æŠ¥å‘Š")
    print("=" * 80)
    
    print(f"ğŸ“… è¯„ä¼°æ—¶é—´: {report['evaluation_info']['timestamp']}")
    print(f"ğŸ¤– æ¨¡å‹ç±»å‹: {report['model_info']['model_type']}")
    print(f"ğŸ“Š æ•°æ®é›†: {report['evaluation_info']['dataset']}")
    print(f"ğŸ–¼ï¸  å¤„ç†å›¾ç‰‡: {report['summary']['total_images']} å¼ ")
    print(f"âš™ï¸  è¶…åˆ†è¾¨ç‡å€æ•°: {report['evaluation_info']['upscale_factor']}x")
    print(f"ğŸ¯ DDPMæ­¥æ•°: {report['evaluation_info']['ddpm_steps']}")
    print(f"ğŸ¨ é¢œè‰²ä¿®å¤: {report['evaluation_info']['colorfix_type']}")
    
    print(f"\nğŸ“ˆ PSNRç»Ÿè®¡:")
    print(f"  - å¹³å‡PSNR: {report['summary']['average_psnr']:.2f} dB")
    print(f"  - æœ€ä½³PSNR: {report['summary']['best_psnr']:.2f} dB")
    print(f"  - æœ€å·®PSNR: {report['summary']['worst_psnr']:.2f} dB")
    
    if report['summary']['average_psnr'] > 0:
        print(f"\nğŸ¯ æ€§èƒ½è¯„ä¼°:")
        if report['summary']['average_psnr'] >= 30:
            print("  âœ… ä¼˜ç§€ - PSNR >= 30dB")
        elif report['summary']['average_psnr'] >= 25:
            print("  âœ… è‰¯å¥½ - PSNR >= 25dB")
        elif report['summary']['average_psnr'] >= 20:
            print("  âš ï¸  ä¸€èˆ¬ - PSNR >= 20dB")
        else:
            print("  âŒ éœ€è¦æ”¹è¿› - PSNR < 20dB")
    
    print(f"\nğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: tra_report_evaluation.json")

def main():
    """ä¸»å‡½æ•°"""
    print("TraReport è¯„ä¼°æŠ¥å‘Šç”Ÿæˆå™¨")
    print("ä½¿ç”¨StableSR Edgeæ¨¡å‹å¯¹DIV2Kæ•°æ®é›†è¿›è¡Œè¯„ä¼°")
    print("=" * 80)
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not torch.cuda.is_available():
        print("âš ï¸  è­¦å‘Š: CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
    
    # æ£€æŸ¥æ•°æ®é›†
    gt_dir = '/stablesr_dataset/dataset/DIV2K/DIV2K_valid_HR'
    val_dir = '/stablesr_dataset/dataset/DIV2K/DIV2K_valid_LR'
    
    if not os.path.exists(gt_dir):
        print(f"âŒ GTç›®å½•ä¸å­˜åœ¨: {gt_dir}")
        return False
    
    if not os.path.exists(val_dir):
        print(f"âŒ Valç›®å½•ä¸å­˜åœ¨: {val_dir}")
        return False
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = './logs/2025-10-05T01-24-44_stablesr_edge_T6_DIV2K_2005_10_04/checkpoints/last.ckpt'
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False
    
    print(f"âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡")
    print(f"âœ… GTç›®å½•: {gt_dir}")
    print(f"âœ… Valç›®å½•: {val_dir}")
    print(f"âœ… æ¨¡å‹æ–‡ä»¶: {model_path}")
    
    # ç”ŸæˆæŠ¥å‘Š
    report = generate_tra_report()
    
    if report:
        generate_summary_report(report)
        print(f"\nğŸ‰ TraReportè¯„ä¼°æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
        return True
    else:
        print(f"\nâŒ TraReportè¯„ä¼°æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
